{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Brandon OBriant\n",
    "# PREDICT 422\n",
    "# Bank Telephone Direct Marketing Campaign: Classifier comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepared for Python version 3x features and functions\n",
    "# seed value for random number generators to obtain reproducible results\n",
    "RANDOM_SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import base packages into the namespace for this program\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import roc_auc_score   \n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function, takes in desired working directory path, changes the working directory\n",
    "# to that path, and prints out the current working directory as a sanity check\n",
    "def change_working_dir(path):\n",
    "    os.chdir(path)\n",
    "    #print(\"Current working directory:{}\".format(str(os.getcwd())))\n",
    "\n",
    "# gets assigned desired working directory--***put your working directory
    "WORKING_DIRECTORY_PATH = ".../MSDS_422_Bank_Marketing_Classifier_Comparison/\"\n",
    "\n",
    "# changes working dir to desire call    \n",
    "change_working_dir(WORKING_DIRECTORY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to load csv file into a DataFrame\n",
    "def load_csv(filename):\n",
    "    data = pd.read_csv(filename, sep = ';')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prints shape of data, if there is no name associated with data (i.e. np.arrar)\n",
    "# then it ommit the associate name\n",
    "def print_shape(data, name = None):\n",
    "    if name != None:\n",
    "        data.name = name\n",
    "        print(\"The shape of data, {}, is: {}\".format(name, str(data.shape)))\n",
    "    else:\n",
    "        print(\"The shape of data is: {}\".format(str(data.shape)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "# drop observations with missing data, if any\n",
    "# examine the shape of input data after dropping missing data    \n",
    "def dropna_print_shape(dataframe, name):\n",
    "        if dataframe.isnull().values.any() == True:\n",
    "            dataframe = dataframe.dropna()\n",
    "            print(\"\\n-----Dropped NAN values------\\n\")\n",
    "            print_shape(dataframe, name)\n",
    "        else:\n",
    "            print(\"\\n-----No NAN values------\\n\")\n",
    "            print_shape(dataframe, name)\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data, bank, is: (4521, 17)\n"
     ]
    }
   ],
   "source": [
    "# initial work with the smaller data set\n",
    "bank = load_csv('bank.csv') \n",
    "# examine the shape of original input data\n",
    "print_shape(bank, 'bank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----No NAN values------\n",
      "\n",
      "The shape of data, bank, is: (4521, 17)\n"
     ]
    }
   ],
   "source": [
    "# drop observations from bank DataFrame with missing data, if any\n",
    "# examine the shape of input data after dropping missing data\n",
    "bank = dropna_print_shape(bank, 'bank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prints information statistics and descriptions about data passed in and \n",
    "# saves it to a txt file for review\n",
    "def print_data_info_save_to_file(data, dataname):\n",
    "    print('\\n---------{} data informations----------\\n'.format(dataname))\n",
    "    print('\\n{} data shape: {}'.format(dataname, data.shape))\n",
    "    print('\\n{} data column values: {}'.format(dataname, data.columns.values)) \n",
    "    print('\\n{} data first few rows: {}'.format(dataname, data.head())) \n",
    "    print('\\n{} data look at end of data: {}'.format(dataname, data.tail()))\n",
    "    print('\\n{} data descriptive statistics: {}'.format(dataname, data.describe()))\n",
    "    with open(\"{}_data_descriptive_information.txt\".format(dataname), \"w\") as text_file:\n",
    "        text_file.write('\\n---------{} data informations----------\\n'.format(dataname)+\n",
    "                        '\\n{} data shape: {}'.format(dataname, str(data.shape)) +\n",
    "                        '\\n{} data column values: {}'.format(dataname, str(data.columns.values)) + \n",
    "                        '\\n{} data first few rows: {}'.format(dataname, str(data.head()))+ \n",
    "                        '\\n{} data look at end of data: {}'.format(dataname, str(data.tail()))+\n",
    "                        '\\n{} data descriptive statistics: {}'.format(dataname, str(data.describe()))+ \n",
    "                        '\\n{} data information: {}'.format(dataname, str(data.info())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------bank data informations----------\n",
      "\n",
      "\n",
      "bank data shape: (4521, 17)\n",
      "\n",
      "bank data column values: ['age' 'job' 'marital' 'education' 'default' 'balance' 'housing' 'loan'\n",
      " 'contact' 'day' 'month' 'duration' 'campaign' 'pdays' 'previous'\n",
      " 'poutcome' 'response']\n",
      "\n",
      "bank data first few rows:    age          job  marital  education default  balance housing loan  \\\n",
      "0   30   unemployed  married    primary      no     1787      no   no   \n",
      "1   33     services  married  secondary      no     4789     yes  yes   \n",
      "2   35   management   single   tertiary      no     1350     yes   no   \n",
      "3   30   management  married   tertiary      no     1476     yes  yes   \n",
      "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
      "\n",
      "    contact  day month  duration  campaign  pdays  previous poutcome response  \n",
      "0  cellular   19   oct        79         1     -1         0  unknown       no  \n",
      "1  cellular   11   may       220         1    339         4  failure       no  \n",
      "2  cellular   16   apr       185         1    330         1  failure       no  \n",
      "3   unknown    3   jun       199         4     -1         0  unknown       no  \n",
      "4   unknown    5   may       226         1     -1         0  unknown       no  \n",
      "\n",
      "bank data look at end of data:       age            job  marital  education default  balance housing loan  \\\n",
      "4516   33       services  married  secondary      no     -333     yes   no   \n",
      "4517   57  self-employed  married   tertiary     yes    -3313     yes  yes   \n",
      "4518   57     technician  married  secondary      no      295      no   no   \n",
      "4519   28    blue-collar  married  secondary      no     1137      no   no   \n",
      "4520   44   entrepreneur   single   tertiary      no     1136     yes  yes   \n",
      "\n",
      "       contact  day month  duration  campaign  pdays  previous poutcome  \\\n",
      "4516  cellular   30   jul       329         5     -1         0  unknown   \n",
      "4517   unknown    9   may       153         1     -1         0  unknown   \n",
      "4518  cellular   19   aug       151        11     -1         0  unknown   \n",
      "4519  cellular    6   feb       129         4    211         3    other   \n",
      "4520  cellular    3   apr       345         2    249         7    other   \n",
      "\n",
      "     response  \n",
      "4516       no  \n",
      "4517       no  \n",
      "4518       no  \n",
      "4519       no  \n",
      "4520       no  \n",
      "\n",
      "bank data descriptive statistics:                age       balance          day     duration     campaign  \\\n",
      "count  4521.000000   4521.000000  4521.000000  4521.000000  4521.000000   \n",
      "mean     41.170095   1422.657819    15.915284   263.961292     2.793630   \n",
      "std      10.576211   3009.638142     8.247667   259.856633     3.109807   \n",
      "min      19.000000  -3313.000000     1.000000     4.000000     1.000000   \n",
      "25%      33.000000     69.000000     9.000000   104.000000     1.000000   \n",
      "50%      39.000000    444.000000    16.000000   185.000000     2.000000   \n",
      "75%      49.000000   1480.000000    21.000000   329.000000     3.000000   \n",
      "max      87.000000  71188.000000    31.000000  3025.000000    50.000000   \n",
      "\n",
      "             pdays     previous  \n",
      "count  4521.000000  4521.000000  \n",
      "mean     39.766645     0.542579  \n",
      "std     100.121124     1.693562  \n",
      "min      -1.000000     0.000000  \n",
      "25%      -1.000000     0.000000  \n",
      "50%      -1.000000     0.000000  \n",
      "75%      -1.000000     0.000000  \n",
      "max     871.000000    25.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      "age          4521 non-null int64\n",
      "job          4521 non-null object\n",
      "marital      4521 non-null object\n",
      "education    4521 non-null object\n",
      "default      4521 non-null object\n",
      "balance      4521 non-null int64\n",
      "housing      4521 non-null object\n",
      "loan         4521 non-null object\n",
      "contact      4521 non-null object\n",
      "day          4521 non-null int64\n",
      "month        4521 non-null object\n",
      "duration     4521 non-null int64\n",
      "campaign     4521 non-null int64\n",
      "pdays        4521 non-null int64\n",
      "previous     4521 non-null int64\n",
      "poutcome     4521 non-null object\n",
      "response     4521 non-null object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 600.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# look at the list of column names, note that y is the response\n",
    "# look at the beginning of the DataFrame\n",
    "# Look at the end of the DataFrame\n",
    "# bank descriptive statistics\n",
    "print_data_info_save_to_file(bank, 'bank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mapping function to convert text no/yes to integer 0/1\n",
    "def map_to_binary(dataframe, feature):\n",
    "    mapped_df = pd.DataFrame()\n",
    "    impute_to_binary = {'no' : 0, 'yes' : 1}\n",
    "    mapped_df = dataframe[feature].map(impute_to_binary)\n",
    "    return mapped_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define binary variable for having credit in default\n",
    "default = map_to_binary(bank, 'default')\n",
    "\n",
    "# define binary variable for having a mortgage or housing loan\n",
    "housing = map_to_binary(bank, 'housing')\n",
    "\n",
    "# define binary variable for having a personal loan\n",
    "loan = map_to_binary(bank, 'loan')\n",
    "\n",
    "# define response variable to use in the model\n",
    "response = map_to_binary(bank, 'response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gather three explanatory variables and response into a numpy array \n",
    "# here we use .T to obtain the transpose for the structure we want\n",
    "model_data = np.array([np.array(default), np.array(housing), np.array(loan), \n",
    "    np.array(response)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data is: (4521, 4)\n"
     ]
    }
   ],
   "source": [
    "# examine the shape of model_data, which we will use in subsequent modeling\n",
    "print_shape(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------Model data statistics----------\n",
      "\n",
      "\n",
      "Model data shape: (4521, 4)\n",
      "\n",
      "\n",
      "Model data mean: 0.21272948462729485\n",
      "\n",
      "\n",
      "Model data standard deviation: 0.40923789047142295\n",
      "\n",
      "\n",
      "Model data standard median: 0.0\n",
      "\n",
      "\n",
      "Model data variance: 0.16747565099750036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prints statistics about data passed in and save it to a txt file for review\n",
    "def print_stats_save_to_file(data, dataname):\n",
    "    print('\\n---------{} data statistics----------\\n'.format(dataname))\n",
    "    print('\\n{} data shape: {}\\n'.format(dataname, data.shape))\n",
    "    print('\\n{} data mean: {}\\n'.format(dataname, np.mean(data)))\n",
    "    print('\\n{} data standard deviation: {}\\n'.format(dataname, np.std(data)))\n",
    "    print('\\n{} data standard median: {}\\n'.format(dataname, np.median(data)))\n",
    "    print('\\n{} data variance: {}\\n'.format(dataname, np.var(data)))\n",
    "    with open(\"model_data_descriptive_stats.txt\", \"w\") as text_file:\n",
    "        text_file.write('\\n---------{} data statistics----------\\n'.format(dataname)+\n",
    "                        '\\n{} data mean: {}'.format(dataname, str(np.mean(data))) + \n",
    "                        '\\n{} data standard deviation: {}'.format(dataname, str(np.std(data)))+ \n",
    "                        '\\n{} data median: {}'.format(dataname, str(np.median(data)))+\n",
    "                        '\\n{} data variance: {}'.format(dataname, str(np.var(data)))+ \n",
    "                        '\\n{} data shape: {}'.format(dataname, str(data.shape)))\n",
    "\n",
    "# prints model_data statistics and saves it to a txt file    \n",
    "print_stats_save_to_file(model_data, 'Model')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle the rows \n",
    "np.random.seed(RANDOM_SEED)\n",
    "np.random.shuffle(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data is: (4521, 4)\n"
     ]
    }
   ],
   "source": [
    "# examine the shape of model_data, after shuffle, which we will use in subsequent modeling\n",
    "print_shape(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of names for classifier models\n",
    "classifier_names = [\"Logistic_Regression\", \"Naive_Bayes\"]\n",
    "\n",
    "# list of classifiers\n",
    "classifiers = [LogisticRegression(), BernoulliNB(alpha=1.0, binarize=0.5, \n",
    "                           class_prior = [0.5, 0.5], fit_prior=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ten-fold cross-validation employed here\n",
    "N_FOLDS = 10\n",
    "\n",
    "# set up numpy array for storing results\n",
    "crossvalidation_results = np.zeros((N_FOLDS, len(classifier_names)))\n",
    "\n",
    "# kf, object,  model selection kfold split set up\n",
    "kf = KFold(n_splits = N_FOLDS, shuffle=False, random_state = RANDOM_SEED)\n",
    "\n",
    "#--check the splitting process by looking at fold observation counts--\n",
    "# fold count initialized to zero\n",
    "index_for_fold = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold index: 0 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4068, 3)\n",
      "X_test: (453, 3)\n",
      "y_train: (4068,)\n",
      "y_test: (453,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.563430790315\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.563430790315\n",
      "\n",
      "Fold index: 1 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4069, 3)\n",
      "X_test: (452, 3)\n",
      "y_train: (4069,)\n",
      "y_test: (452,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.629634353741\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.629634353741\n",
      "\n",
      "Fold index: 2 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4069, 3)\n",
      "X_test: (452, 3)\n",
      "y_train: (4069,)\n",
      "y_test: (452,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.662648809524\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.662648809524\n",
      "\n",
      "Fold index: 3 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4069, 3)\n",
      "X_test: (452, 3)\n",
      "y_train: (4069,)\n",
      "y_test: (452,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.614750267094\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.614750267094\n",
      "\n",
      "Fold index: 4 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4069, 3)\n",
      "X_test: (452, 3)\n",
      "y_train: (4069,)\n",
      "y_test: (452,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.660968440594\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.660968440594\n",
      "\n",
      "Fold index: 5 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4069, 3)\n",
      "X_test: (452, 3)\n",
      "y_train: (4069,)\n",
      "y_test: (452,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.576391115182\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.576391115182\n",
      "\n",
      "Fold index: 6 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4069, 3)\n",
      "X_test: (452, 3)\n",
      "y_train: (4069,)\n",
      "y_test: (452,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.60390752198\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.60390752198\n",
      "\n",
      "Fold index: 7 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4069, 3)\n",
      "X_test: (452, 3)\n",
      "y_train: (4069,)\n",
      "y_test: (452,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.567118226601\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.569260012851\n",
      "\n",
      "Fold index: 8 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4069, 3)\n",
      "X_test: (452, 3)\n",
      "y_train: (4069,)\n",
      "y_test: (452,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.603557940767\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.603557940767\n",
      "\n",
      "Fold index: 9 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (4069, 3)\n",
      "X_test: (452, 3)\n",
      "y_train: (4069,)\n",
      "y_test: (452,)\n",
      "\n",
      "Classifier evaluation for: Logistic_Regression\n",
      "  Scikit Learn method: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Area under ROC curve: 0.596756803381\n",
      "\n",
      "Classifier evaluation for: Naive_Bayes\n",
      "  Scikit Learn method: BernoulliNB(alpha=1.0, binarize=0.5, class_prior=[0.5, 0.5], fit_prior=False)\n",
      "Area under ROC curve: 0.596756803381\n"
     ]
    }
   ],
   "source": [
    "# splits the data, fits the classifier models, returns the crossvalidation\n",
    "# results\n",
    "for train_index, test_index in kf.split(model_data):\n",
    "    print('\\nFold index:', index_for_fold,\n",
    "          '------------------------------------------')\n",
    "    # 0:model_data.shape[1]-1 slices for explanatory variables,\n",
    "    X_train = model_data[train_index, 0:model_data.shape[1]-1]\n",
    "    X_test = model_data[test_index, 0:model_data.shape[1]-1]\n",
    "    \n",
    "    # model_data.shape[1]-1 is the index for the response variable\n",
    "    y_train = model_data[train_index, model_data.shape[1]-1]\n",
    "    y_test = model_data[test_index, model_data.shape[1]-1]\n",
    "    \n",
    "    # prints structure of data after split for x, y \n",
    "    print('\\nShape of input data for this fold:',\n",
    "          '\\nData Set: (Observations, Variables)')\n",
    "    print('X_train:', X_train.shape)\n",
    "    print('X_test:',X_test.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "    print('y_test:',y_test.shape)\n",
    "    \n",
    "    # index for method initialized to zero\n",
    "    index_for_method = 0\n",
    "    \n",
    "    # loops through classifiers\n",
    "    # fits the respective model\n",
    "    # performs predictions\n",
    "    for name, clf in zip(classifier_names, classifiers):\n",
    "        print('\\nClassifier evaluation for:', name)\n",
    "        print('  Scikit Learn method:', clf)\n",
    "        \n",
    "         # fit current classifier model using train data set\n",
    "        clf.fit(X_train, y_train) \n",
    "        \n",
    "        # calculate predictions to evaluate, using test set for this fold\n",
    "        y_test_predict = clf.predict_proba(X_test)\n",
    "        \n",
    "        # calculates ROC AUC score, stores results in cv_results\n",
    "        fold_method_result = roc_auc_score(y_test, y_test_predict[:,1]) \n",
    "        print('Area under ROC curve:', fold_method_result)\n",
    "        crossvalidation_results[index_for_fold, index_for_method] = fold_method_result\n",
    "        \n",
    "        \n",
    "        # adds one to the index, next loop will be the next classifier\n",
    "        index_for_method += 1\n",
    "        \n",
    "    # adds one to the index, next loop will be the next split in fold    \n",
    "    index_for_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas DataFrame gets assigned cross fold evaluation results\n",
    "crossvalidation_results_df = pd.DataFrame(crossvalidation_results)\n",
    "crossvalidation_results_df.columns = classifier_names\n",
    "with open(\"cv-results-df.txt\", \"w\") as text_file:\n",
    "    text_file.write('\\nResults from '+ str(N_FOLDS) + '-fold cross-validation\\n'+\n",
    "                     '\\nMethod Area under ROC Curve:\\n'+ \n",
    "                     str(crossvalidation_results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Average results from 10-fold cross-validation\n",
      "\n",
      "Method Area under ROC Curve:\n",
      "Logistic_Regression    0.607916\n",
      "Naive_Bayes            0.608131\n",
      "dtype: float64\n",
      "\n",
      "Mean of cross validation result:\n",
      "Logistic_Regression    0.607916\n",
      "Naive_Bayes            0.608131\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print mean of ROC AUC evaluation results for each classifier, saves to file\n",
    "print('\\n----------------------------------------------')\n",
    "print('\\nAverage results from {}-fold cross-validation\\n\\nMethod Area under ROC Curve:\\n{}'\n",
    "      .format(str(N_FOLDS),str(crossvalidation_results_df.mean())), sep = '')     \n",
    "print('\\nMean of cross validation result:\\n{}'.format(crossvalidation_results_df.mean())) \n",
    "with open(\"cv-results-df-mean.txt\", \"w\") as text_file:\n",
    "    text_file.write('\\nAverage results from {}-fold cross-validation\\n\\nMethod Area under ROC Curve:\\n{}'\n",
    "                    .format(str(N_FOLDS),str(crossvalidation_results_df.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
